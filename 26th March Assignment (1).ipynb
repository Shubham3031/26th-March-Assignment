{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4bbff-dc94-4642-9d67-d64a3c4c8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Ans.\n",
    "\n",
    "Simple linear regression is a statistical method used to model the relationship between two variables, \n",
    "where one variable is the independent variable and the other is the dependent variable. \n",
    "The relationship between the two variables is represented by a straight line. \n",
    "Simple linear regression involves fitting a line to a set of data points and using that line to make \n",
    "predictions about the dependent variable based on the independent variable. \n",
    "For example, a simple linear regression model could be used to predict the salary of an employee \n",
    "based on their years of experience.\n",
    "\n",
    "Multiple linear regression, on the other hand, is a statistical method used to model the relationship\n",
    "between multiple independent variables and a dependent variable. The relationship is still represented \n",
    "by a straight line, but the line is now a function of multiple independent variables. \n",
    "Multiple linear regression involves fitting a line to a set of data points that have multiple\n",
    "independent variables and using that line to make predictions about the dependent variable.\n",
    "For example, a multiple linear regression model could be used to predict the price of a house\n",
    "based on its square footage, number of bedrooms, and number of bathrooms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19a24e-a1d8-4592-ae13-8b11440ba686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Ans.\n",
    "\n",
    "Linear regression makes several assumptions about the data in order to provide accurate results. \n",
    "These assumptions include:\n",
    "\n",
    "Linearity: The relationship between the dependent variable and the independent variable(s) is linear.\n",
    "\n",
    "Independence: The observations are independent of each other.\n",
    "\n",
    "Homoscedasticity: The variance of the errors is constant across all levels of the independent variable(s).\n",
    "\n",
    "Normality: The errors are normally distributed.\n",
    "\n",
    "No multicollinearity: There is no perfect linear relationship among the independent variables.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, there are several methods:\n",
    "\n",
    "Scatter plots: Creating scatter plots of the dependent variable against each independent variable can \n",
    "help assess linearity and identify any outliers.\n",
    "\n",
    "Residual plots: Residual plots can help check for homoscedasticity, normality, and the presence of outliers.\n",
    "\n",
    "Normal probability plots: Normal probability plots of the residuals can help check for normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a444dd-9f1f-4fb6-8e96-3d4282f1b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Ans.\n",
    "\n",
    "In a linear regression model, the slope represents the change in the dependent variable (Y) for\n",
    "every unit change in the independent variable (X), while the intercept represents the value of \n",
    "the dependent variable (Y) when the independent variable (X) is equal to zero.\n",
    "\n",
    "For example, let's say we want to predict a person's salary based on their years of experience.\n",
    "We can use a linear regression model to do so, where the independent variable is years of experience (X) \n",
    "and the dependent variable is salary (Y). The linear regression equation would be:\n",
    "\n",
    "Y = b0 + b1*X\n",
    "\n",
    "Where b0 is the intercept and b1 is the slope.\n",
    "\n",
    "If the intercept (b0) is 30,000 and the slope (b1) is 5,000, this means that the predicted salary of someone \n",
    "with zero years of experience (when X=0) would be 30,000. For every additional year of experience, we\n",
    "would expect the salary to increase by 5,000.\n",
    "\n",
    "Therefore, if someone had 3 years of experience, we could predict their salary using the equation:\n",
    "\n",
    "Y = 30,000 + 5,000*3 = 45,000\n",
    "\n",
    "This means that we would expect their salary to be 45,000, assuming that the relationship between years \n",
    "of experience and salary is linear and the model is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00f4a1-7944-4399-ae3b-1774d3943148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Ans.\n",
    "\n",
    "Gradient descent is an optimization algorithm used to minimize the cost function of a machine learning model.\n",
    "The cost function is a mathematical function that measures the difference between the predicted output and the\n",
    "actual output for a given input. The goal of the optimization algorithm is to find the values of the model \n",
    "parameters that minimize the cost function.\n",
    "\n",
    "Gradient descent is used in machine learning to train many types of models, including linear regression, \n",
    "logistic regression, and neural networks. It is a powerful optimization algorithm that can find the optimal\n",
    "parameters of a model even for complex problems with many features. However, it is sensitive to the choice \n",
    "of learning rate, and it may get stuck in local minima if the cost function has multiple minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c4221-36da-4aa0-b461-c389174de5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Ans.\n",
    "\n",
    "Multiple linear regression is a statistical modeling technique used to predict a dependent \n",
    "variable based on multiple independent variables.\n",
    "In multiple linear regression, the dependent variable Y is modeled as a linear function of two or more independent variables X1, X2, ..., Xn, each with its own regression coefficient β1, β2, ..., βn. The multiple linear regression equation is given by:\n",
    "\n",
    "Y = β0 + β1X1 + β2X2 + ... + βn*Xn + ε\n",
    "\n",
    "where β0 is the intercept or constant term, and ε is the error term.\n",
    "\n",
    "The main difference between multiple linear regression and simple linear regression is the number\n",
    "of independent variables used in the model. In simple linear regression, there is only one independent\n",
    "variable, while in multiple linear regression, there are two or more independent variables.\n",
    "Additionally, multiple linear regression allows for the study of the joint effects of multiple\n",
    "independent variables on the dependent variable, while simple linear regression only allows for\n",
    "the study of the effect of one independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08086a3f-c185-4eab-bff2-cdafee4ed47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.Ans.\n",
    "\n",
    "Multicollinearity is a problem that can occur in multiple linear regression when two or\n",
    "more independent variables in the model are highly correlated with each other. \n",
    "This can cause the coefficients of the independent variables to be unstable and difficult to interpret, \n",
    "and can also lead to incorrect inferences about the relationships between the independent variables and \n",
    "the dependent variable.\n",
    "\n",
    "There are several ways to detect multicollinearity in a multiple linear regression model. \n",
    "\n",
    "One way is to calculate the correlation matrix between the independent variables, and look \n",
    "for high correlation coefficients (e.g., greater than 0.7 or 0.8). Another way is to use a\n",
    "statistical test, such as the variance inflation factor (VIF), which measures the extent to\n",
    "which the variance of the estimated coefficients is inflated due to multicollinearity.\n",
    "\n",
    "If multicollinearity is detected in a multiple linear regression model, there are several ways to\n",
    "address the issue:\n",
    "\n",
    "Remove one or more of the highly correlated independent variables from the model. This can be done\n",
    "based on theoretical grounds or using statistical methods such as stepwise regression or principal\n",
    "component analysis.\n",
    "\n",
    "Combine the highly correlated independent variables into a single variable. This can be done using\n",
    "techniques such as factor analysis or clustering.\n",
    "\n",
    "Regularize the model using techniques such as ridge regression or lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd556f-37c5-4d20-9121-903335e9d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Ans.\n",
    "\n",
    "Polynomial regression is a type of regression analysis in which the relationship between the independent \n",
    "variable x and the dependent variable y is modeled as an nth degree polynomial. In other words, instead of \n",
    "fitting a straight line (as in linear regression), polynomial regression fits a curve to the data.\n",
    "\n",
    "The general equation for polynomial regression with one independent variable is:\n",
    "\n",
    "y = β0 + β1x + β2x^2 + … + βn*x^n + ε\n",
    "\n",
    "where y is the dependent variable, x is the independent variable, β0, β1, β2, ..., βn are the coefficients \n",
    "(also known as parameters), ε is the error term, and n is the degree of the polynomial.\n",
    "\n",
    "Polynomial regression allows us to model more complex relationships between the independent and \n",
    "dependent variables than linear regression. For example, if the relationship between x and y is not \n",
    "linear, but rather curved, then a polynomial regression model may be more appropriate. Additionally,\n",
    "polynomial regression can fit better to the data when there are many fluctuations or spikes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4693083-7b7f-4c9d-8c65-1859db6659a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Ans.\n",
    "\n",
    "Polynomial regression is a type of regression analysis in which the relationship between the independent\n",
    "variable x and the dependent variable y is modeled as an nth degree polynomial. Linear regression, on the\n",
    "other hand, is a type of regression analysis in which the relationship between the independent variable x\n",
    "and the dependent variable y is modeled as a linear equation.\n",
    "\n",
    "Advantages of polynomial regression compared to linear regression:\n",
    "\n",
    "Flexibility: Polynomial regression is more flexible than linear regression as it can fit a wider range of\n",
    "curves. It can capture non-linear relationships between the independent and dependent variables.\n",
    "\n",
    "Better accuracy: In situations where the relationship between the independent and dependent variables is \n",
    "non-linear, polynomial regression can provide better accuracy than linear regression.\n",
    "\n",
    "Improved R-squared value: Polynomial regression can have a higher R-squared value than linear regression,\n",
    "indicating that it is better able to explain the variance in the dependent variable.\n",
    "\n",
    "Disadvantages of polynomial regression compared to linear regression:\n",
    "\n",
    "Overfitting: Polynomial regression models with high degree polynomials can overfit the data, which means\n",
    "that the model becomes too complex and may not generalize well to new data.\n",
    "\n",
    "Increased complexity: As the degree of the polynomial increases, the complexity of the model also increases,\n",
    "making it more difficult to interpret the results.\n",
    "\n",
    "Extrapolation: Polynomial regression models can be unreliable when extrapolating beyond the range of the\n",
    "data used to fit the model.\n",
    "\n",
    "In situations where the relationship between the independent and dependent variables is non-linear, polynomial\n",
    "regression can be preferred over linear regression. For example, in finance, stock prices often exhibit\n",
    "non-linear relationships with economic indicators such as interest rates, inflation, and GDP.\n",
    "In physics, polynomial regression can be used to model the relationship between the force applied\n",
    "to an object and its resulting acceleration. In general, polynomial regression can be used in situations\n",
    "where the underlying relationship between the independent and dependent variables is not linear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
